This is a scratchpad of what might feel like to program in xprl.

It's rapidly becoming yeat another attempt to organise a sprawling spiral of
research. That's okay; I really don't know where I want to take this yet.

Initially I'm writing the language in itself to make sure it's sufficiently
thought out to do something useful.

Bootstrapping is going to be fun.

* Reading List
   - [ ] Lambda the Ultimate Declarative — Steele 1976
     | It is not the names which are important to the computation, but rather    |
     | the quantities; hence it is appropriate to focus on the quantities and    |
     | think of them as having one or more names over time, rather than thinking |
     | of a name as having one or more values over time.                         |

     From section 1.3. I don't know if I've ever seen that point of view so
     clearly stated. And in 1976...

     The argument by induction (section 1.5) that no lambda expression ever
     actually pops the control stack strikes me as profound.

     Only primitives ever pop return addresses off the control stack in a
     functionally implemented language. To convert that language to
     continuation passing style, it suffices to convert just the
     primitives. Except for those lambdas that now want to manipulate control
     flow...

     So we only need to focus on the primitives. But what are the primitives?
     Primitives are *other interpreters* to whom we send messages. Furthermore
     those other interpreters are defined by code and the interpreter of the
     other interpreter's code.

     This is a tower that ends up reaching down to machine code for each
     primitive. That sounds like a lot of work, but isn't that just what
     implementing a language is?

     This focus on interpreters all the way down means that we need contracts
     of some sort to be enforced. After all, what use is it knowing that `+` is
     an interpreter whose code is X and whose parent interpreter is `lli`, if
     we can't use that information to replace `+` with an interpreter whose
     code is JIT compiled and optimised? Or with code that can be passed to a
     parent interpreter on a different platform which doesn't support the
     current parent?

     I truly feel like I'm making progress, but this is certainly taking me in
     a spiral.
   - [ ] Lambda: The Ultimate Imperative
   - [ ] Actors: A Model of Concurrent Computation in Distributed Systems
   - [X] Intensions and Extensions in a Reflective Tower, Danvy & Malmkjær 1988
   - [X] The Mystery of the Tower Revealed, Wand & Friedman 1988
   - [X] The Theory of Fexprs is Trivial, Wand 1998
     I've read the intro of this paper before and took it as a dismissal fexprs
     and mathematically uninteresting, which I believe is the general takaway in
     the community.

     But doesn't that mean that we have a solution to function equality? That is
     to say, does this paper actually prove that a lisp interpreter can be
     qualitatively more powerful than the lambda calculus? I definitely need to
     read this now. The implications for robust engineering are impossible to
     overstate if that's the case, even if the math is boring.
     After rereading sections of this paper, I still don't understand the details of
     the argument, but the meaning seems more relevant. It has to do with optimising
     compilers and source rewriting: if context is so important that only identical
     things (in context) are equal, then the compiler has to have insight into the
     semantics of the program because purely syntactic transformations are
     impossible.

     This seems to be more because sytax and semantics cease to be separate domains
     that can be operated upon individually. Thus the entire formailst ediface is
     inapplicable and so on and so on.

     That doesn't seem so bad. But it does mean that we need a new way of
     expressing the meaning of a program.
   - [X] Mathematical Foundations of Joy
     Denotational semantics is such an unsatisfying interpretation of
     meaning. Syntax and semantics are strictly separated
     because.... because. Computers are formal symbol manipulators, which is
     another way of saying they're purely syntactic.

     So syntax is an algebraic construct of some sort (a monoid in Joy's case)
     and we want to relate it to semantics. So why don't we find a homomorphism
     of some sort from our syntactic algebra to some other algebra and call that
     other algebra the semantics?

     Okay, awesome. But what the hell does it mean?

     We've lost the point. What does it mean to say "A means B"?

     What if one tried to build a language semantics on Bateson's slash?

     Semantics aside, the notion that every word is a function from stack to
     stack (or in a more general sense from context of evaluation to context of
     evaluation) is a fascinating perspective. Om takes this even further by
     viewing every word as a function from continuation to continuation.

     What if eval only operated on the environment? That env moving around the
     system is in a real sense the entire computation up to this point. We can't
     know what inputs are going to come in (think repl development), but we
     always know to what that new code will be applied.
   - [X] Reification: Reflection without Metaphysics; Friedman, Wand 1984
   - [ ] Brian Smith's Phd Thesis
     This thing is 762 pages long. That's just crazy. But judging by the table
     of contents, the first 150 pages or so are likely to be full of useful
     insight.
   - [ ] Reread The Early History of Smalltalk
   - [ ] Art of the Metaobject Protocol
     You know a book is above your paygrade when you read it and think "Hey they
     didn't do anything." and then realise that they've implemented an entire
     language without you noticing.
* Languages to learn more about
  - Factor
  - Joy
  - See where Unison has gotten
  - Minikanren and relational programming in general
  - CLOS
  - Go
    Comparatively boring choice? Well people who work in go day to day always
    tell me the same thing: go is boring and yet incredibly productive. They get
    everything done and go home early on a regular basis.

    That is the most understated attestation of excellence I've ever heard. I
    want to see it in action. Cool is only useful to draw the crowd.
  - Microthreading
    Not a language per se, but an interesting idea.
* Questions
** [2022-09-28 Wed 12:26] def, intern, and purity
   If there are no side effects, how does one implement `def`?

   You don't. We need side effects somewhere, but they have to be constrained to
   the communication layer.

   I think of the communication layer as a hypergraph (though I keep coming back
   to the idea of using symplectic topology to analyse it, so maybe simplicial
   complexes are a better foundation...) where the edges are the emission
   channels (one writer, potentially many readers) and the nodes are either

   1) Pure computations which commence when a message is available on each input
      channel and terminate with a map from channels to lists of messages.
   2) Sources, which take no input, but emit (potentially infinitely many)
      messages to their output channels.
   3) Sinks, which receive messages but emit nothing.

   Sources and sinks are the edge conditions of the system. Sources allow
   repeatable interaction with things like time, PRNGs, etc. by logging the
   messages.

   Sinks, on the otherhand are the escape valve that lets us do anything we have
   to do. Sinks have to able to do anything, otherwise we can't implement the
   language, but they also need to be heavily restricted most of the time,
   otherwise we'll never be able to understand what a program might do.

   To implement `intern`, we would need a sink/source pair where the sink
   receives messages saying "merge this form into the trie", and the source
   emits messages saying "Ref has been merged into tree". The actual magic lives
   in the gap between sink and source.

   Sending messages over a network is the same sort of proposition. We need a
   sink that takes request data, creates sources which will eventually emit
   reponse data (or errors), sends those new sources somewhere, then sends the
   request and sets up the response listeners.

   It seems painfully intricate and potentially a point of failure. But I hope
   that pushing these details to the edge of the system will make the centre
   much easier to manipulate and reason about. Time will tell.

** [2022-09-28 Wed 12:42] Multimethods and static linking
   The biggest failing point of multimethods, in my experience, is that they are
   global mutable variables, so suddenly the behaviour of your program depends
   upon the order in which code modules get loaded.

   Ultimately it's unavoidable that the compiler has to know about the code you
   want to call before it can emit the code for the call.

   My solution (at present) is to make it so that polymorphism is restricted to
   the set of methods known to the reader when the code making the recursive
   call is read. That way the developer can inspect the set of possible methods
   (fixed), and make sure the one they expect is present. The actual dispatch
   still happens at runtime, but the choices are fixed at dev time. Incidentally
   it should also be possible for the developer to add annotations reducing the
   size of the set of possible implementations to 1, thus ensuring the jit will
   insert a direct call, when that's needed.

   The two layers of buzzpop should make this simple to implement. Every
   concrete method is interned in the form trie, but when a name is overridden,
   one of two things must happen.

   1) If the name is known to be a simple indirection, then the name trie gets
      updated, and you need to use time travel to find what the name used to be
      for things read in in the past.
   2) If the old and new versions of the name point to indirect indirections,
      then we can merge those indirect indirections. Note that the trie is still
      updated with history so that previous versions of the dispatch table can
      be referred to. This allows one symbol to point to different sets of
      methods depending on the relative points at which the references and
      definitions of that symbol are read.

   That sounds absurdly complicated. And it is. But that complication is
   inherent in the problem of building an intertwingled dynamic system by
   linearly scanning source files.

   One of my core goals is to prevent the programmer from being able to lie to
   themselves about what they do and do not know.

** [2022-10-06 Thu 09:19] Context and fexprs
   The most common issue I've been having with a complete lack of side effects
   is the maintenance of local state. The language itself needs to keep internal
   state so that new defs can be referred to later on.

   Modelling state as function sending results back to two locations is a
   kludge. It's not that dissimilar to the state monad in that it keeps state
   hidden away inside some secret loop that isn't readily accessible except when
   necessary.

   That's the wrong way to go about it entirely.

** [2022-10-06 Thu 10:23] Reflection and Semantics in Lisp
   Brian Cantwell Smith 1984

   I'd forgotten how much influence this paper has had on my thinking. Rereading
   it now, I'm seeing that a large portion of my meandering theories are just
   attempts to rephrase and understand his basic idea of reflection.

   For instance, Smith's equation relating denotation to operation in lisp:

   ∀ s ∈ S, if ϕ(s) ∈ S then ψ(s) = ϕ(s) else ϕ(ψ(s)) = ϕ(s)

   Is exactly what I've been calling "generalised homoiconicity".

   It says, loosely, that if a form denotes a form, then the interpretation of
   the form *is* its meaning. Otherwise the meaning of the form is the meaning
   of its interpretation.

   Hickey's emphasis on making literal data syntactically explicit actually
   makes the equation above much easier to understand. I don't think I would
   ever have seen the significance without having programmed in clojure.

   It shouldn't be surprising that my ideas aren't original. Ideas are never
   fully original. Now that I've remembered where these originate, I have some
   reading to do:

   - [ ] A Simple Reflective Interpreter, Jefferson & Friedman 1996
   - [ ] Intensions and Extensions in a Reflective Tower, Danvy & Malmkjær 1988
   - [ ] The Mystery of the Tower Revealed, Wand & Friedman 1988
   - [ ] The Theory of Fexprs is Trivial, Wand 1998
     I've read the intro of this paper before and took it as a dismissal fexprs
     and mathematically uninteresting, which I believe is the general takaway in
     the community.

     But doesn't that mean that we have a solution to function equality? That is
     to say, does this paper actually prove that a lisp interpreter can be
     qualitatively more powerful than the lambda calculus? I definitely need to
     read this now. The implications for robust engineering are impossible to
     overstate if that's the case, even if the math is boring.
** [2022-10-07 Fri 12:00] More Reflection on Reflection and Semantics in Lisp
   At the end of section 7, Smith writes "It is noteworthy that no reflective
   proceedures need to be primitive; even LAMBDA can be built up from scratch."

   Here's the implementation of λ:

   (define lambda
     (lambda reflect [[kind pattern body] env cont]
       (cont (ccons kind ↑env pattern body))))

   So all lambdas are defined in terms of lambda reflect. That's really cool,
   but we have a bootstrapping problem: lambda reflect needs to be built in
   before lambda can be defined. Isn't that a necessary reflective primitive?

   Need to read Smith and des Rivières 1984 to see how they break the cycle.

   Does he not consider bootstrapped circuit breakers to be primitive, or am I
   missing something?

   The initial lambda implementation is very important since it's an opening
   for Thompson quines.

   But beyond security considerations, it's that circuit breaking kludge that
   shows the lie of lisp, by itself, as a full theory of computing
   machinery. Something else needs to exist for a lisp to be built on top of,
   and how lisp is implemented in that something else determines the ultimate
   reach.

   So what if instead of having an initial lambda in terms of which lambda is
   defined, we had a call down to a lower level which explicitely says
   "`lambda` at the lisp level is defined in terms of `lambda` in the
   substrate."? What is the substrate? That's an implementation concern, but it
   could be anything from raw hex up to clojure, it depends on what the
   language is implemented in.

   Or perhaps, more concisely, it depends on the interpreter of the interpreter
   that we call "lisp".

   The tower can be arbitrarily high, but it goes down to the hardware and ends
   there always. How high it goes depends on how much reflection an application
   needs, and how far below on what tech stack is used to build it.

   The "programming language" is always in the middle of a tower. If the
   language is sufficiently expressive we build up from the language to
   something higher, but even the least expressive of languages are implemented
   in something else all the way down to machine code, or microcode, or verilog
   and fpga layout, depending on how far you want to look.

   The height of stacks nowadays is often lamented as a problem. Languages like
   go and rust which compile right to machine code are one way of getting
   around that problem, but they do it by restricting how high the programmer
   can climb (because the compiler has to understand everything top to bottom
   and that's just too hard in general for any program we can currently
   write).

   I'm thinking the opposite. Allow the stack to grow as high as necessary to
   express the program you want to write as cleanly as possible. Simple,
   obviously correct programs sitting on top of many layers of progressively
   more complex but tractible abstractions. But keep the stack explicit. The
   tower of technologies is invisible to the programmer who doesn't care, but
   is always available for inspection, debugging, tooling, or optimising.

   After all, once you have the simple and elegant solution, the best way to
   optimise it is to quash the inner layers of abstraction while preserving the
   simple surface.

   Ultimately, even though 3-lisp defines lambda as a userspace function, the
   meaning and behaviour of that function will always depend on the behaviour
   of an invisible kludge that was shoved in to get it all started and then
   deleted and forgotten about.
** [2022-10-13 Thu 10:43] Reflection without infinity
   The approach of Friedman and Wand is intriguing, but the `meaning` builtin
   seems like a mistake. The builtin "spin up a new interpreter and run code
   there (using this interpreter to interpret that interpreter)" is a clever
   hack to avoid the infinite tower. Something similar, though poorly formed,
   occured to me when reading Smith's paper in the first place.

   But do we really need that `meaning` operator. And perhaps more importantly,
   do we want to spin up a copy of the *same* interpreter, or give the user the
   ability to define new interpreters at will and embed them within the code?

   Take the macro definition in fexpr.xprl (as of now). What we have is a sort
   of meta evaluation protocol. `eval` dispatches on the type of its
   argument. Lists being the primary metaphor for passing information around in
   lisp, `(eval ^List ...)` invokes `apply` which is where the bulk of lisp
   happens.

   But `eval` passes on expressions without evaluating them, and `apply` itself
   dispatches on type — and I'm allowing specification to instances in this case
   (though I ought to namespace qualify everything in advance) — the combined
   effect being that I can specialise `apply` to the symbol `xprl.core/fn` and
   have apply create a datastructure representing a function declaration (*not*
   a compiled proceedure). Then when `apply` is called on one of these function
   objects, it does what you expect (evals the args, binds the results to the
   function arguments, and then evaluates the result). But we can dispatch
   `apply` on the symbol `xprl.core/macro` as well, creating a different kind of
   datastructure (which is really the same as a function object but of a
   different type) and then not evaluate the arguments passed to a macro
   object.

   `xprl.core/fn` and `xprl.core/macro` are effectively keywords since they're
   defined as specialisations of the interpreter itself. But the user can define
   new keywords in the same way freely. They can even define their own
   interpreter and completely replace the builtin one (though the builtin one
   will be interpreting it, which maybe I can avoid).

   But back to reflection. When the programmer is able to define new *expression
   types* they can control what is evaluated when and thus manipulate the
   datastructures that are going to be evaluated before passing them to
   eval. That's reflection. If the user wants to manipulate the new expression
   type before its version of eval/apply gets invoked, they can define yet
   another expression type and indirect evaluation another level. And so on ad
   nauseum.

   I've never seen any practical use in using reflection more than 2 levels
   deep, but maybe I just haven't been looking. With this metaeval protocol we
   can reflect as deeply as we need to, but we have to do the work of setting up
   each new level as we go. More work, less magic. I think that's a good trade.

   Going back to a second to the idea of lists being the metaphor for message
   passing in lisp: a list is considered to be the implicit invocation of a
   function with arguments. Or seen from a message passing point of view, a list
   is a specification '(f & args) that says "send the message `args` to `f`
   (after interpreting what is meant by args) and wait for a response."

   With continuations we don't need to worry about waiting for responses since f
   will either yield to some process of its own accord, or yield back to the
   current continuation (as a return value), but we don't care, that's up to f.

   So what if `f` is another interpreter? and especially what if it's another
   interpreter messaged from tail position that never returns to the calling
   interpreter? This is the sort of setup I'm looking for to bootstrap higher
   level languages that are capable of stepping down to lower layers for interop
   purposes.

   It's also a way to have a conceptually deep stack with lots of descriptive
   layers that aid development and debugging, but can be stripped away entirely
   when performance is the main concern.

   But I'm getting way ahead of myself.
** [2022-10-18 Tue 10:25] Microthreading
    Cf http://subdivi.de/~helmut/libmuth/tutorial.html,
    https://en.wikipedia.org/wiki/Micro-thread_(multi-core)

    I'm finding a glut of resources on concurrency, and basically nothing on
    parallelism. Continuations can build any concurrent construct (as far as
    I've seen mentioned), but what about constructs (either theory or patterns)
    to run many continuations in parralel?

    There are resources like Goetz's book on concurrency in java, that contain a
    lot of practical advice on how to build reliable software based on an
    adversarial thread model.

    But not a lot on new models. Data parallelism, task parallelism, actors,
    CSP,... that's pretty much it.

    Microthreads, as above (I have no idea what libmuth was, but the tutorial is
    short and well written) are just functions intended to be run in
    parallel. But the model is still threading, with semaphores and the
    rest. The main innovation in the Cell archtectures mentioned is extending
    the ISA to make microtaskswitching more efficient. That might be an
    improvement of the von Neumann bottleneck, but our current hardware is still
    going to dead end with the scorpion.

    But there's nothing here that wasn't in erlang. Run one scheduler per core
    and keep a queue of coroutines (or whatever you want to call them). It seems
    like the state of the art hasn't moved since I was born. Or it might be
    better to say it's been going in circles.

    I can squeeze what I'm building into these paradigms: Program execution
    generates a stream of thunks which get enqueued and multiple schedulers (one
    per core) pop thunks off the queue and run them. Data dependencies are
    generally sorted out because you don't have a thunk until you have all the
    data. One thunk can generate data and pass it on to a continuation which
    uses it to make (and enqueue) another thunk.

    It's not very pretty, but I think it works. Implementation will tell where
    the weakest parts of the hand waving lie.
