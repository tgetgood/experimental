#+TITLE: Native Code Generator

The ultimate goal of this project is to develop a novel high level language that
integrates cpu and gpu programming. That language has been described elsewhere
(but is by no means fully thought out).

This document will discuss a tower of languages to build the base of it.

* Desiderata and Priorities
** A REPL
   The entire goal of this is to create a fast feedback experience, so it is
   critical that we can JIT compile and link the code at human realtime speeds.

   Specifically this means that we need <10ms compile times — an arbitrary but
   sufficient goal — so that you don't notice the fact that everything you type
   is being compiled and linked into the session.

   In particular, this prohibits global compiler optimisations, or anything else
   that inhibits incremental compilation of (very) small units.
** Bootstrapping
   That said it's entirely possible that the lasagna described below is just too
   slow to be practical, but if we can use the slow lasagna to compile itself
   into a fast enough executable, then we win.

   Sort of.

   Of course the goal is to bootstrap, but the goal will never be to reimplement
   clojure, so we would lose the full power of clojure and the tooling that
   comes with it.

   That's inevitable as you build a new language which is not hosted nor
   embedded in another. It's a difficult loss though, and postponing it as much
   as possible is desirable.

   Would it be feasible to bootstrap the runtime, but keep the clojure front
   end? By front end I mean nrepl, the reader, cider, etc.. That's an
   interesting idea.
** A Sufficiently Smart Runtime
   This is the real goal of the entire endeavour. Very high level code generates
   lower level code which generates code which ... until you get words being
   pushed between registers.

   Most low level tools see the language source as the last step. Only compiler
   devs and hardware nuts should be looking at the *output* of the compiler,
   right? No, the output of the compiler is just more code. The compiler is just
   more code, all of it should be traceable and debuggable at runtime and as
   much as possible should be compiled away in production.

   There's no intention of having code that is fast from a machine or micro
   benchmark point of view. The only goal is to have complex software which is
   fast from a human point of view. The small wins of static optimisation get
   you stuck in (I conjecture very low) local optima. By being slower in a way
   which people will barely notice, we can be faster in the long run.

   Modern software doesn't do something and halt. Nearly all meaningful software
   is meant to run indefinitely until someone shuts it down or the power goes
   out.

   Hotspot does what I want, but it doesn't remember as well as it should. of
   course memory has a cost, but storage is so fast and cheap nowadays. Also
   hotspot is the result of a million phds, but hopefully I can just crib a lot
   of ideas from that work.
** Local First
   Locality is a forest. We have caches (always more than one nowadays and the
   L1 caches of different cores are relativistically distant frames of
   reference), ram, local disk (nvme is faster today than DDR2 was), and network
   storage.

   There's also a parallel branch the goes from the gpu cache to vram to main
   ram to ...

   None of that has much to do with what I mean by local first, so let's try
   again.

   You device should work perfectly well without any network connection. Ideally
   your device should keep working when hard disks, gpus, or other pieces are
   removed.

   That means redundancy, which is easy to confuse with waste, but the value
   will — I hope — become apparent.
* Levels of Abstraction
  I've chosen to implement this directly on the llvm after evaluating many
  options. The ultimate reason is simplicity. I need to interact with hardware,
  so choices are already constrained (C, assembly, Rust, etc.). So why llvm? The
  short version is that assembly isn't portable, rust is too tightly coupled to
  its stack based notion of lifetimes (plus the type system is mostly a
  hinderance in this kind of exploratory work), and C, well I don't want to
  write it in C.

  But I also don't want to be writing IR. I want to step away from the IR type
  system immediately, minimal though it is. I want to talk about message
  passing, and not about jumping to labels, etc.. But these things must be
  built.

  A lot of this is inspired by the intermediate representations developed for
  falloleen.
** IR as Data
   Step 1 is just to capture IR instructions as clojure data. There's no need to
   model all instructions initially, but only those needed for subsequent layers.

   [:add :i32 127 438]

   perhaps. That might well prove simplistic, but there's a good chance it won't
   since instructions are just lines of text — multi line instructions are for
   presentation, it would appear, but that needs to be verified.

   Globals (starting with =@=) will need to be munged since the @ character
   cannot be present in keywords or symbols. Maybe just use strings?

   (with-meta [:add :i32 127 438]
     {:properties [nuw nsw]
      :result-register %1})

   "nuw" should always be set from higher level perspectives, but remember that
   this is supposed to model IR.

   Should I be using spec for this? It seems like a clear use case in some
   ways.

   Blocks are just lists of instructions:

   (with-meta [inst1 inst2 ...]
     {:label G__0027})

   Is metadata the right way to think about return registers, block labels,
   instruction property switches, etc.? It's convenient because it leaves the
   instructions themselves simple and quickly readable, but it's inconvenient
   because it hides this info unless you know to look for it.

   An alternate representation would just put the code into the metamap:

   {:return %4
    :inst [:udiv :i8 14 %3]}

   Where a function would be

   {:args []
    :properties ...
    :name ...
    :blocks [{:label, :instructions}]}

   The =call= instruction will be a bit special. Not very.

   This representation is intended to be machine generated and machine consumed,
   so being overly explicit is best.

   I'll need to play with some simple programs to see if this makes any sense.
** High Level Representation
   There are a lot of aspects of IR which are needlessly verbose. Arrays and
   Vectors need to be homogeneous, but the type of each element needs to be
   specified. A lot of type inference is trivial. Simple proceedures, like macros,
   would reduce work enourmously.

   In the spirit of lisp, we can build up the platform instead of just digging down
   from the language we're trying to write.

   I'll need to spend more time working with IR and get the data representation
   working before really designing this. This bit is art, not engineering.
** A minimal lisp
   What's the minimal set of constructs we need to have a lisp?

   Going back to basics, we need lambda, conditional branch, values, names
   (name values, determine if a value is a name, dereference a name to get a
   value), and datastructures (cons, car, cdr, traditionally, but we'll go with
   EDN).

   Plus, to be useful, we'll build in arithmetic and not reimplement it from the
   lambda calculus.

   Builtin list

   - fn
   - cond
     - comparisons
   - values
     - strings (vectors of chars? ropes? just literal strings for the moment)
     - integers (will build all arithmetic from ints ourselves)
     - true/false
   - edn (no cons cells or lists, sets will come in a later iteration).
     - []
     - {}
     - conj
     - get
   - names
     Taking a hint from llvm's SSA, namespaced names can be assigned
     immutably. This will make some reply things difficult, but we'll figure
     that out.

     We still need assignment and dereference operations.
   - math
     - arithmetic
     - comparison (equality test)
   - string manipulation?
     We need some way to manipulate strings. Being able to treat them as a data
     structure that can be manipulated by collection abstractions would suffice.
** Tranductive programming
   You can build general recursion (and super-Church computation) from primitive
   recursive functions using self referrential transduction networks.

   There are drawbacks: halting becomes a non-issue because these networks don't
   halt (they can become inactive, but proving they will stay so is in general
   beyond my current means).

   The input streams to the transduction network can be from sensors and physical
   transducers. Input streams with real entropy allow a transduction network to
   output non-computable numbers (a là Wegner's identity machines), that are not
   just noise. Whether useful work can be accomplished thereby is still to be
   establised.
* Homeless features
** global reference by value (infinite hash set)
** Automatic transients
   This will require support from the allocator, but once we have a reference count
   on every reference (they don't need to be threadsafe on the stack) we will know
   dynamically when it's safe to mutate a value in place, and when we need to
   create a new one.
** binary destructuring
   This will be needed for interacting effectively with gpus, maybe for simd
   cpu opts as well, but to a lesser extent.
** symbolic arithmetic
* Questions
  At what level of abstraction do we introduce name-by-value to the language
  tower?

  Where do I have to start en
  Where do we insert the runtime optimisation heuristics?

  Is it possible to write a branchless filter transducer? Not that this is all
  that important, but it probably is a pretty simple thing to do that will bring
  some benefits being at the very bottom.
* Reading
** https://stackoverflow.com/questions/71707983/dynamic-linking-without-libc
   An attempt to link in Vulkan without libc. A failed attempt, but I don't even
   know where to start.
** https://releases.llvm.org/13.0.0/docs/Reference.html#api-reference
   LLVM docs index page. Not just IR.
** Scheduling on GPUs
   https://lirias.kuleuven.be/retrieve/268015

   Paper about code generation for GPU computations.
* Research Agenda
  I desperately need to organise my reading and take better notes.

  The proximate goal is to write a minimal lisp repl with native interop.

  The native interop is initially to work with vulkan. But to generate the
  structs and calls vulkan expects, I need to parse that giant xml file, so I
  should do that at compile time using a stable language (initially).

  So what do I want from the repl, specifically? What is the minimal useful repl
  for interactive development? Do I need to be able to create new ffi calls at
  runtime?

  Do I even need the any of the rpl steps to be in the host language? Is my bogo
  compiler fast enough to type code into a clojure repl, have it compile and
  execute flubless, and pipe the response back to the clojure repl?

  Pros:
    - mature toolchain
    - familiar
    - easier to get going
  Cons:
    - Do I need to implement interop between clj and flubless to pass data back
      and forth?

      Actually, I don't think I do. I can return edn from flubless, but I'll
      need to translate the inputs from clj to something flubless can
      understand.

    - Rube Goldbergundian
    - slow. But too slow?

  Unsolved issues:
    - How does a jit compiler work? How do you replace the machine code
      currently being executed?

      Do I care at present? Can I just define a code unit (a flub in this case)
      which is the basic building block of the program, write a super naive
      interpreter for it, and then pull in llvm to do jit compilation and just
      edit the function symbols, tables, whatever to use the faster code?

      I really don't understand enough about compilers to even express this
      problem. This is going to be an ugly program. At least I'll learn what not
      to do.

    - The JVM is not a great fit for this. Is it good enough, or am I coasting
      on what's familiar?

      The problem with the jvm approach is that I can't embed anything, which
      means everything available at runtime has to be compiled. I can't start
      with a foreign runtime and slowly replace parts of it as I go.

      I should definitely look into other platforms on which I can directly
      interoperate with C code without all of the nuissance required in the
      JVM.

      Possible candidates: Go, Nim, Zig, Julia, why not just C? you know why not.

      The simpler the type system and the more interactive the development cycle
      the better. It could be quite a while before I have the system
      sufficiently bootstrapped to work on it from within.
